{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Train And Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train and Test on raw data after removing stopwords and using Tf-Idf but No Extra Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smsData = pd.read_csv('C:\\\\DataSets\\\\SmsSpam\\\\TRAIN_SMS.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stop Words and Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopList = list(stopwords.words('english')) # Stopwords\n",
    "cleaned = []\n",
    "for i in range(len(smsData['Message'])):\n",
    "    clean = smsData['Message'][i]\n",
    "    clean = clean.lower().split()\n",
    "    clean = [word for word in clean if word not in stopList]\n",
    "    clean = ' '.join(str(w) for w in clean)\n",
    "    #print(clean)\n",
    "    cleaned.append(clean)\n",
    "\n",
    "intLabel = smsData['Label'].copy()\n",
    "i=0\n",
    "for l in intLabel:\n",
    "    if l == 'ham':\n",
    "        intLabel[i]=0\n",
    "    elif l == 'spam':\n",
    "        intLabel[i]=1\n",
    "    else:\n",
    "        intLabel[i]=2\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IntLabel</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>oh how abt 2 days before Christmas</td>\n",
       "      <td>oh abt 2 days christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>info</td>\n",
       "      <td>Welcome to OVATION HOLD R.No. 184, 114, 395, 3...</td>\n",
       "      <td>welcome ovation hold r.no. 184, 114, 395, 378 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>info</td>\n",
       "      <td>Thank you for using your ICICI bank CREDITcard...</td>\n",
       "      <td>thank using icici bank creditcard ending 5253 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>schedule a meeting with the entire team in the...</td>\n",
       "      <td>schedule meeting entire team office tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Tommy is my brother</td>\n",
       "      <td>tommy brother</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IntLabel Label                                            Message  \\\n",
       "0        0   ham                 oh how abt 2 days before Christmas   \n",
       "1        2  info  Welcome to OVATION HOLD R.No. 184, 114, 395, 3...   \n",
       "2        2  info  Thank you for using your ICICI bank CREDITcard...   \n",
       "3        0   ham  schedule a meeting with the entire team in the...   \n",
       "4        0   ham                                Tommy is my brother   \n",
       "\n",
       "                                             Cleaned  \n",
       "0                            oh abt 2 days christmas  \n",
       "1  welcome ovation hold r.no. 184, 114, 395, 378 ...  \n",
       "2  thank using icici bank creditcard ending 5253 ...  \n",
       "3       schedule meeting entire team office tomorrow  \n",
       "4                                      tommy brother  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smsData.insert(loc=2, column=\"Cleaned\", value=cleaned)\n",
    "smsData.insert(loc=0, column=\"IntLabel\", value=intLabel)\n",
    "smsData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\"english\")\n",
    "X = vectorizer.fit_transform(smsData['Cleaned'])\n",
    "#print(X)\n",
    "Y = smsData['IntLabel'].values.astype('int')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,stratify=Y,test_size=.4) #stratify to ensure proportion of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=3000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifier = OneVsRestClassifier(LinearSVC(max_iter=3000))\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  0.9924166666666666\n",
      "F1 Score :  0.9924166666666666\n",
      "Confusion Matrix : \n",
      " [[3985   11    4]\n",
      " [  76 2574    0]\n",
      " [   0    0 5350]]\n",
      "\n",
      "Clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4000\n",
      "           1       1.00      0.97      0.98      2650\n",
      "           2       1.00      1.00      1.00      5350\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.99      0.99      0.99     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,classification_report\n",
    "predicted = classifier.predict(X_test)\n",
    "print (\"Accuracy Score : \",accuracy_score(Y_test, predicted))\n",
    "print (\"F1 Score : \",accuracy_score(Y_test, predicted))\n",
    "print (\"Confusion Matrix : \\n\",confusion_matrix(Y_test, predicted))\n",
    "print ('\\nClasification report:\\n', classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above results are just by using raw data with little cleaning, it would be nice to see if extra features like message length etc., analyzed in data exploration phase help in improving our result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Including Message Length As Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\anaconda3\\envs\\python35\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  0.9961666666666666\n",
      "F1 Score :  0.9961666666666666\n",
      "Confusion Matrix : \n",
      " [[3985   15    0]\n",
      " [  29 2619    2]\n",
      " [   0    0 5350]]\n",
      "\n",
      "Clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4000\n",
      "           1       0.99      0.99      0.99      2650\n",
      "           2       1.00      1.00      1.00      5350\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     12000\n",
      "   macro avg       1.00      0.99      1.00     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#length of message in its original form, not the cleaned one\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix,hstack,csr_matrix\n",
    "smsData['length'] = smsData['Message'].map(lambda msg: len(msg))\n",
    "smsData['msgTfIdf']=list(X)\n",
    "metadata = csr_matrix(smsData['length'].values).T\n",
    "NewData = hstack([X, metadata]).tocsr()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(NewData,Y,stratify=Y,test_size=.4) #stratify to ensure proportion of classes\n",
    "classifier = OneVsRestClassifier(LinearSVC(max_iter=3000))\n",
    "classifier.fit(X_train, Y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print (\"Accuracy Score : \",accuracy_score(Y_test, predicted))\n",
    "print (\"F1 Score : \",accuracy_score(Y_test, predicted))\n",
    "print (\"Confusion Matrix : \\n\",confusion_matrix(Y_test, predicted))\n",
    "print ('\\nClasification report:\\n', classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we see there is an increase in accuracy by .4 % by including message length in the data.\n",
    "### We might need to scale the features to address the convergence problem as SVM tends to be sensitive to features scaling\n",
    "#### We may hope to expect further increase in accuracy by inculing other features that we discovered in data exploration phase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
